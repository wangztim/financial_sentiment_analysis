{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import os\n","import re\n","from glob import glob\n","from ast import literal_eval\n","from sklearn.model_selection import train_test_split\n","\n","import tensorflow as tf\n","\n","import transformers\n","from transformers import DistilBertTokenizerFast, TFDistilBertForSequenceClassification, DistilBertConfig"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Detect hardware, return appropriate distribution strategy\n","tpu = None\n","strategy = tf.distribute.get_strategy()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# CONFIG VARIABLES\n","AUTO = tf.data.experimental.AUTOTUNE\n","PRE_TRAINED_MODEL_NAME = 'distilbert-base-uncased'\n","LOADING = True # True if loading from storage, False if generating variables from scratch\n","BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n","MAX_TOKEN_LENGTH = 160\n","EPOCHS = 2\n","LEARNING_RATE = 3e-5"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":["if LOADING:\n","    messages = pd.read_parquet(\"/kaggle/input/short-financial-messages/all_messages.parquet\")\n","else:\n","    WORKING_DIR = '/kaggle/input/'\n","    ticker_dir = WORKING_DIR + 'short-financial-messages/data/'\n","    PATH = ticker_dir\n","    EXT = \"*.csv\"\n","\n","    all_csv_files = [file\n","                     for path, subdir, files in os.walk(PATH)\n","                     for file in glob(os.path.join(path, EXT))]\n","\n","    parse_csv = lambda file: pd.read_csv(file, parse_dates=['created_at'], converters={\"symbols\": literal_eval})\n","\n","    messages = pd.concat((parse_csv(f) for f in all_csv_files), ignore_index=True, sort=False)\n","\n","    messages.set_index('id', inplace=True)\n","    messages.index = messages.index.map(str)\n","    messages = messages[~messages.index.duplicated(keep='first')]\n","\n","    filter_urls = lambda text: re.sub(r\"http\\S+\", \"\", str(text))\n","    messages['body'] = messages['body'].apply(filter_urls)\n","\n","    messages[\"sentiment\"] = messages[\"sentiment\"].replace({-1: 0})\n","    messages.to_parquet(\"all_messages\")"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["messages_alt = messages.copy()\n","labeled = messages[messages['sentiment'] != -69]\n","labeled[\"is_spam\"] = -69 * np.ones(len(labeled), dtype=np.int)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["spam_words = [\n","    \"smartoptionsÂ®\",\n","    \"technical alerts\",\n","    \"stop-loss: available to subscribers\",\n","    \"evolution trading\",\n","    \"trade alerts\",\n","    \"trading community\",\n","    \"trading alerts\",\n","    \"sweepcast.com\",\n","    \"optionpros\",\n","    \"freedomstocks.ca\",\n","    \"thetradexchange\",\n","    \"capotrades\",\n","    \"thetradexchange\",\n","    \"pineapplestocks.com\",\n","    \"alert triggered\",\n","    \"xtradesb\",\n","    \"option-alerts.com\",\n","    \"options alert\"\n","    \"alerts triggered\",\n","    \"assetdash.com\",\n","    \"beststocksnowapp.com\",\n","    \"drstoxx.com\",\n","    \"echelon-1.com\",\n","    \"wallstjesus.com\",\n","    \"trendspider.com\",\n","    \"gainers watchlist\",\n","    \"freedom stocks\",\n","    \"#optionstradingpulse\",\n","    \"vwapindicator\",\n","    \"on notifications\",\n","    \"trade ideas\",\n","    \"(delayed)\",\n","    'follow for'\n","]\n","\n","spam_indices = [\n","    \"189934349\",\n","    \"142590793\",\n","    \"185792536\",\n","    \"182362237\",\n","    \"226578494\",\n","    \"174519289\",\n","    \"240723002\",\n","    \"242183678\",\n","    \"248681269\",\n","    \"245656196\",\n","    \"243413941\",\n","    \"239273922\",\n","    \"230980738\",\n","    \"255520798\",\n","    \"158019671\",\n","    \"252711617\",\n","    \"252527668\",\n","    \"247522334\",\n","    \"251021498\"\n","]"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["duplicate_indices = [\n","    '59c3b6f2-9238-4198-a18c-7718168f17a4',\n","    '00c563b4-fb57-41a6-9639-36b29c9e895b',\n","    'e7bb7d78-3dca-47dd-9124-7c2b81cb60bf',\n","]"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["tokenizer = DistilBertTokenizerFast.from_pretrained(PRE_TRAINED_MODEL_NAME)\n","vocab_set = set()\n","for symbols in labeled['symbols']:\n","    if symbols is not None and len(symbols) > 0:\n","        for w in symbols:\n","            vocab_set.add(w)\n","tokenizer.add_tokens(list(vocab_set))\n","    \n","def tokenize(input_strings):\n","    return tokenizer.batch_encode_plus(\n","        input_strings, \n","        max_length=MAX_TOKEN_LENGTH, \n","        padding=\"max_length\",\n","        return_tensors='tf', \n","        truncation=True)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["## It seems that FIQA and FPB data serves as good enough for nonspams, not going to pick out 1000 examples by hand\n","good_indices = labeled[~labeled.index.isin(duplicate_indices)].iloc[:3000].index\n","labeled.loc[good_indices, \"is_spam\"] = 0\n","\n","spams = labeled[\"body\"].str.contains('|'.join(spam_words), regex=True)\n","bad_indices = spams[spams == True].index.union(pd.Index(spam_indices))\n","labeled.loc[bad_indices, \"is_spam\"] = 1\n","\n","all_indices = good_indices.union(bad_indices)\n","\n","\n","dataset = labeled.loc[all_indices]"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["x_train, x_test, y_train, y_test = train_test_split(dataset, dataset[\"is_spam\"], shuffle=True)\n","x_test, x_val, y_test, y_val = train_test_split(x_test, x_test[\"is_spam\"], shuffle=True)\n","\n","x_train_tokens = tokenize(x_train['body'].tolist())\n","x_test_tokens = tokenize(x_test['body'].tolist())\n","x_val_tokens = tokenize(x_val['body'].tolist())"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["config = DistilBertConfig(num_labels=2, return_dict=True)\n","model = TFDistilBertForSequenceClassification.from_pretrained(PRE_TRAINED_MODEL_NAME, config=config)\n","model.resize_token_embeddings(len(tokenizer))\n","optimizer = transformers.AdamWeightDecay(learning_rate=LEARNING_RATE)\n","loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n","model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["train_dataset = (\n","    tf.data.Dataset\n","    .from_tensor_slices((dict(x_train_tokens), y_train))\n","    .batch(BATCH_SIZE)\n","    .prefetch(AUTO)\n",")\n","\n","val_dataset = (\n","    tf.data.Dataset\n","    .from_tensor_slices((dict(x_val_tokens), y_val))\n","    .batch(BATCH_SIZE)\n","    .cache()\n","    .prefetch(AUTO)\n",")\n","\n","test_dataset = (\n","    tf.data.Dataset\n","    .from_tensor_slices((dict(x_test_tokens), y_test))\n","    .batch(BATCH_SIZE)\n",")"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["train_history = model.fit(\n","    train_dataset,\n","    validation_data=val_dataset,\n","    epochs=EPOCHS,\n",")"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["model.evaluate(test_dataset, verbose=1)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["all_tokens = tokenize(messages_alt['body'].tolist())\n","\n","full_dataset =  (\n","    tf.data.Dataset\n","    .from_tensor_slices((dict(all_tokens)))\n","    .batch(2 * BATCH_SIZE)\n",")\n","    \n","res = model.predict(full_dataset)\n","all_results = np.argmax(res.logits)\n","messages_alt[\"is_spam\"] = all_results\n","messages_alt.to_parquet(\"spam_be_gone.parquet\")"],"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.7.9 64-bit ('stocktwits_nlp': conda)","metadata":{"interpreter":{"hash":"843da69ca2ee4f0b534085b112099b4edb437f1dbfafcc3afae3619b662602df"}}},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.7.9-final","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}